{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features setup correctly\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, Conv2D\n",
    "import numpy\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from features import Features\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk import tokenize\n",
    "\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "\n",
    "trained_model = None\n",
    "f = Features()\n",
    "f.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global fasttext_model\n",
    "\n",
    "discourse = ['other', 'agreement', 'announcement', 'appreciation', 'humor', 'answer', 'elaboration', 'negativereaction',\n",
    "             'question', 'disagreement']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fasttext():\n",
    "    global fasttext_model\n",
    "    fasttext_model = load_facebook_model('wiki-news-300d-1M-subword.bin')\n",
    "\n",
    "def get_data(filename):\n",
    "    load_json_data = []\n",
    "    count = 0\n",
    "    with open(filename) as jsonfile:\n",
    "        for line in jsonfile:\n",
    "            jline = json.loads(line)\n",
    "            load_json_data.append(jline)\n",
    "            count += 1\n",
    "    return load_json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(load_data):\n",
    "    global errors\n",
    "    global f\n",
    "    count = 0\n",
    "    count_no_author = 0\n",
    "    count_no_title = 0\n",
    "    process_data_list = []\n",
    "    process_label_list = []\n",
    "    for jline in load_data:\n",
    "        author = None\n",
    "        if 'author' in jline['posts'][0]:\n",
    "            author = jline['posts'][0]['author']\n",
    "        for post in jline['posts']:\n",
    "            try:\n",
    "                # Structure\n",
    "                features = f.getStructureFeatures(jline, post['id'])\n",
    "                # Content\n",
    "                if 'body' in post:\n",
    "                    features.append(fasttext_Vec(post['body']))\n",
    "                else:\n",
    "                    features.append(numpy.zeros(300))\n",
    "                    count_no_title += 1\n",
    "                    \n",
    "                # ge66t the vector for the parent body\n",
    "                features.append(fasttext_Vec(f.getParentBody(jline, post['id'])))\n",
    "                # Author\n",
    "                features.append(f.isSameAuthor(jline, post))\n",
    "                \n",
    "                if 'author' in post:\n",
    "                    features.append(fasttext_Vec(post['author']))\n",
    "                    \n",
    "                    if author == post['author']:\n",
    "                        features.append(numpy.full(300, 1.0))\n",
    "                    else:\n",
    "                        features.append(numpy.full(300, 0.0))\n",
    "                else:\n",
    "                    features.append(numpy.zeros(300))\n",
    "                    features.append(numpy.zeros(300))\n",
    "                    count_no_author += 1\n",
    "                \n",
    "                \n",
    "                \n",
    "                if 'title' in jline:\n",
    "                    features.append(fasttext_Vec(jline['title']))\n",
    "                else:\n",
    "                    features.append(numpy.zeros(300))\n",
    "                    \n",
    "                \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                # Community\n",
    "                if 'subreddit' in jline:\n",
    "                    features.append(fasttext_Vec(jline['subreddit']))\n",
    "                else:\n",
    "                    features.append(numpy.zeros(300))\n",
    "                    \n",
    "                # Thread\n",
    "                features += f.thread_info(jline)\n",
    "                feature_nparr = numpy.array(features)\n",
    "                label = discourse.index(post['majority_type'])\n",
    "                process_label_list.append([label])\n",
    "                process_data_list.append(feature_nparr)\n",
    "            except Exception as e:\n",
    "                count += 1\n",
    "    print(\"Total exception count: \" + str(count))\n",
    "    print(\"No authors: \" + str(count_no_author))\n",
    "    print(\"No titles: \" + str(count_no_title))\n",
    "    process_data_list = numpy.array(process_data_list)\n",
    "    process_label_list = numpy.array(process_label_list)\n",
    "    print(process_data_list.shape)\n",
    "    print(process_label_list.shape)\n",
    "    print(\"done processing\")\n",
    "    return process_data_list, process_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_model(data):\n",
    "    global trained_model\n",
    "    input_shape = data[0].shape\n",
    "    # After trying a bunch of different methods, this one worked the best\n",
    "    t_model = tf.keras.Sequential([\n",
    "        \n",
    "        Bidirectional(LSTM(100, input_shape=input_shape, return_sequences=True)),\n",
    "        Bidirectional(LSTM(100)),\n",
    "        #Bidirectional(LSTM(64)),\n",
    "        Dropout(0.5),\n",
    "        #tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    t_model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['categorical_accuracy'])\n",
    "    trained_model = t_model\n",
    "\n",
    "def train(data, labels):\n",
    "    global trained_model\n",
    "    checkpoint_path = 'training_1/cp.ckpt'\n",
    "    set_model(data)\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
    "    trained_model.fit(data, to_categorical(labels), validation_split=0.1, epochs=10, batch_size=64, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasttext_Vec(body):\n",
    "    global fasttext_model\n",
    "    global lemmatizer\n",
    "    global tokenizer\n",
    "    tokens = tokenizer.tokenize(body)\n",
    "    output = numpy.zeros(300)\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            output = numpy.add(output, fasttext_model[lemmatizer.lemmatize(token)])\n",
    "        except KeyError:\n",
    "            output = numpy.add(output, numpy.zeros(300))\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total exception count: 14718\n",
      "No authors: 13841\n",
      "No titles: 0\n",
      "(101639, 16, 300)\n",
      "(101639, 1)\n",
      "done processing\n",
      "Train on 81311 samples, validate on 20328 samples\n",
      "Epoch 1/5\n",
      "81280/81311 [============================>.] - ETA: 0s - loss: 1.1286 - categorical_accuracy: 0.6203\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15ad2f710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "81311/81311 [==============================] - 177s 2ms/step - loss: 1.1287 - categorical_accuracy: 0.6203 - val_loss: 1.0555 - val_categorical_accuracy: 0.6407\n",
      "Epoch 2/5\n",
      "81280/81311 [============================>.] - ETA: 0s - loss: 1.0251 - categorical_accuracy: 0.6497\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15ad2f710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "81311/81311 [==============================] - 171s 2ms/step - loss: 1.0251 - categorical_accuracy: 0.6497 - val_loss: 1.0275 - val_categorical_accuracy: 0.6459\n",
      "Epoch 3/5\n",
      "81280/81311 [============================>.] - ETA: 0s - loss: 0.9961 - categorical_accuracy: 0.6554\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15ad2f710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "81311/81311 [==============================] - 174s 2ms/step - loss: 0.9960 - categorical_accuracy: 0.6554 - val_loss: 1.0093 - val_categorical_accuracy: 0.6480\n",
      "Epoch 4/5\n",
      "81280/81311 [============================>.] - ETA: 0s - loss: 0.9713 - categorical_accuracy: 0.6591\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15ad2f710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "81311/81311 [==============================] - 176s 2ms/step - loss: 0.9713 - categorical_accuracy: 0.6591 - val_loss: 1.0081 - val_categorical_accuracy: 0.6499\n",
      "Epoch 5/5\n",
      "81280/81311 [============================>.] - ETA: 0s - loss: 0.9524 - categorical_accuracy: 0.6647\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15ad2f710>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "81311/81311 [==============================] - 176s 2ms/step - loss: 0.9523 - categorical_accuracy: 0.6646 - val_loss: 1.0010 - val_categorical_accuracy: 0.6525\n"
     ]
    }
   ],
   "source": [
    "global data\n",
    "global labels\n",
    "\n",
    "load_fasttext()\n",
    "json_data = get_data(\"coarse_discourse_dump_reddit.jsonlist\")\n",
    "data, labels = process_data(json_data)\n",
    "train(data, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "json_data = get_data(\"coarse_discourse_dump_reddit.jsonlist\")\n",
    "data, labels = process_data(json_data)\n",
    "train(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 91475 samples, validate on 10164 samples\n",
      "Epoch 1/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 1.0780 - categorical_accuracy: 0.6300\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 120s 1ms/step - loss: 1.0779 - categorical_accuracy: 0.6300 - val_loss: 1.0379 - val_categorical_accuracy: 0.6390\n",
      "Epoch 2/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.9575 - categorical_accuracy: 0.6625\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 118s 1ms/step - loss: 0.9575 - categorical_accuracy: 0.6626 - val_loss: 1.0271 - val_categorical_accuracy: 0.6400\n",
      "Epoch 3/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.9200 - categorical_accuracy: 0.6716\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 126s 1ms/step - loss: 0.9201 - categorical_accuracy: 0.6716 - val_loss: 0.9811 - val_categorical_accuracy: 0.6512\n",
      "Epoch 4/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.8945 - categorical_accuracy: 0.6808\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 123s 1ms/step - loss: 0.8945 - categorical_accuracy: 0.6808 - val_loss: 0.9848 - val_categorical_accuracy: 0.6525\n",
      "Epoch 5/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.8696 - categorical_accuracy: 0.6883\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 123s 1ms/step - loss: 0.8697 - categorical_accuracy: 0.6883 - val_loss: 0.9985 - val_categorical_accuracy: 0.6435\n",
      "Epoch 6/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.8451 - categorical_accuracy: 0.6977\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 122s 1ms/step - loss: 0.8450 - categorical_accuracy: 0.6977 - val_loss: 0.9878 - val_categorical_accuracy: 0.6489\n",
      "Epoch 7/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.8203 - categorical_accuracy: 0.7040\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 121s 1ms/step - loss: 0.8203 - categorical_accuracy: 0.7041 - val_loss: 0.9922 - val_categorical_accuracy: 0.6445\n",
      "Epoch 8/10\n",
      "91456/91475 [============================>.] - ETA: 0s - loss: 0.7949 - categorical_accuracy: 0.7139\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x15fff33c8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "91475/91475 [==============================] - 121s 1ms/step - loss: 0.7950 - categorical_accuracy: 0.7139 - val_loss: 1.0163 - val_categorical_accuracy: 0.6439\n",
      "Epoch 9/10\n",
      " 5120/91475 [>.............................] - ETA: 1:57 - loss: 0.7642 - categorical_accuracy: 0.7238"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-f74f0241490f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-8bc857aa7667>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data, labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mset_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mcp_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2985\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 2986\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   2987\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2988\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_body(load_data):\n",
    "    global vectorizer\n",
    "    global f\n",
    "    count = 0\n",
    "    body = []\n",
    "    for jline in load_data:\n",
    "        for post in jline['posts']:\n",
    "            try:\n",
    "                body.append(post['body'])\n",
    "            except Exception as e:\n",
    "                count += 1\n",
    "    print(count)\n",
    "    print(len(body))\n",
    "    print(\"done processing\")\n",
    "    X = vectorizer.fit_transform(body)\n",
    "    print(len(vectorizer.get_feature_names()))\n",
    "    a = vectorizer.transform([\"I love you\"])\n",
    "    print(a.toarray()[0].shape)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2364\n",
      "113993\n",
      "done processing\n",
      "1423081\n",
      "(1423081,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<113993x1423081 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4480868 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_body(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fasttext_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-decbc5a091d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfasttext_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hi'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fasttext_model' is not defined"
     ]
    }
   ],
   "source": [
    "fasttext_model['hi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
